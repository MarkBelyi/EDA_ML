{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NYC Taxi Data Training Pipeline with Mage and MLflow\n",
    "\n",
    "## Overview\n",
    "Create a training pipeline for the [NYC Yellow taxi dataset (March 2023)](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page) using Mage as an orchestration tool and MLflow for experiment tracking and model registration.\n",
    "\n",
    "## Tasks\n",
    "\n",
    "### 1. ðŸ³ Deploy Mage with Docker\n",
    "**Task**: Launch Mage using Docker Compose following the quick start guidelines.\n",
    "\n",
    "**Question**: Identify the running Mage version from the UI.\n",
    "\n",
    "### 2. ðŸ“ Project Setup\n",
    "**Task**: Initialize a new project named \"homework_10\".\n",
    "\n",
    "**Question**: Check the generated `metadata.yaml` file and report the number of lines it contains.\n",
    "\n",
    "Options:\n",
    "- 35 lines\n",
    "- 45 lines\n",
    "- 55 lines\n",
    "- 65 lines\n",
    "### 3. ðŸ”„ Creating a Pipeline\n",
    "**Task**: Create a data ingestion code block for the March 2023 Yellow taxi trips data.\n",
    "\n",
    "**Question**: How many records were loaded from the dataset?\n",
    "\n",
    "Options:\n",
    "- 3,003,766\n",
    "- 3,203,766\n",
    "- 3,403,766\n",
    "- 3,603,766\n",
    "\n",
    "### 4. ðŸ”§ Data Preparation\n",
    "**Task**: Create a transformer code block using the provided data preparation logic for Yellow taxi dataset.\n",
    "\n",
    "**Code Template**:\n",
    "```python\n",
    "   \n",
    "   df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "   df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "   \n",
    "   df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "   df.duration = df.duration.dt.total_seconds() / 60\n",
    "   \n",
    "   df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "   \n",
    "   categorical = ['PULocationID', 'DOLocationID']\n",
    "   df[categorical] = df[categorical].astype(str)\n",
    "```\n",
    "\n",
    "   ### 5. ðŸ¤– Train a Model\n",
    "**Task**: Create a transformation block to train a linear regression model using the following steps:\n",
    "\n",
    "Steps:\n",
    "1. Fit a dict vectorizer\n",
    "2. Train a linear regression model with default parameters\n",
    "3. Use pickup and dropoff locations as separate features (no combination)\n",
    "\n",
    "**Requirements**:\n",
    "- Create a transformation block\n",
    "- Return both dict vectorizer and model\n",
    "- Print the `intercept_` field in the code block\n",
    "\n",
    "**Question**: What is the intercept value of the trained model?\n",
    "\n",
    "Options:\n",
    "- 21.77\n",
    "- 24.77\n",
    "- 27.77\n",
    "- 31.77\n",
    "\n",
    "Note:\n",
    "- Use the same code structure as in homework 8\n",
    "- The transformation block should output both vectorizer and model objects\n",
    "\n",
    "### 6. ðŸ“ Register the Model with MLflow\n",
    "**Task**: Set up MLflow and save the trained model.\n",
    "\n",
    "1. First, stop the current docker-compose or use Ctrl + C to stop:\n",
    "```bash\n",
    "docker-compose down\n",
    "```\n",
    "2. Create mlflow.dockerfile:\n",
    "\n",
    "```bash\n",
    "FROM python:3.10-slim\n",
    "\n",
    "RUN pip install mlflow==2.12.1\n",
    "\n",
    "EXPOSE 5000\n",
    "\n",
    "CMD [ \\\n",
    "    \"mlflow\", \"server\", \\\n",
    "    \"--backend-store-uri\", \"sqlite:///home/mlflow_data/mlflow.db\", \\\n",
    "    \"--host\", \"0.0.0.0\", \\\n",
    "    \"--port\", \"5000\" \\\n",
    "]\n",
    "```\n",
    "\n",
    "3. Add MLflow service configuration to `docker-compose.yaml`:\n",
    "\n",
    "```yaml\n",
    "mlflow:\n",
    " build:\n",
    "   context: .\n",
    "   dockerfile: mlflow.dockerfile\n",
    " ports:\n",
    "   - \"5000:5000\"  # Expose MLflow UI port\n",
    " volumes:\n",
    "   - \"${PWD}/mlflow_data:/home/mlflow_data/\"  # Mount MLflow data directory\n",
    " networks:\n",
    "   - app-network\n",
    "   ```\n",
    "### MLflow Setup and Model Export\n",
    "\n",
    "1. **Network Configuration**:\n",
    "- Ensure `app-network` in MLflow configuration matches your Mage and Postgres network\n",
    "- This allows communication between all services\n",
    "\n",
    "2. **Dependencies**:\n",
    "- Verify `mlflow==2.12.1` is in `requirements.txt` of your Mage project\n",
    "- Add it if starting fresh\n",
    "\n",
    "3. **Create Data Exporter Block**:\n",
    "\n",
    "**Task**: Create a new block to:\n",
    "- Log the linear regression model\n",
    "- Save and log the dict vectorizer artifact\n",
    "\n",
    "**MLflow Access**:\n",
    "- MLflow UI should be available at `http://mlflow:5000`\n",
    "- Create exporter block to interact with MLflow\n",
    "\n",
    "**Question**: Check the logged MLModel file and report the model size (`model_size_bytes` field):\n",
    "\n",
    "Options:\n",
    "- 14,534\n",
    "- 9,534\n",
    "- 4,534\n",
    "- 1,534\n",
    "\n",
    "Note: It's common practice to combine the model logging and artifact saving in a single code block."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
