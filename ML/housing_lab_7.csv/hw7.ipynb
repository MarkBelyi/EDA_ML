{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### In this homework, we will use the California Housing Prices again \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "You have to:\n",
    "* Use the same dataset as in homework #3.\n",
    "* Filter the data to include only records where ocean_proximity is either '<1H OCEAN' or 'INLAND'.\n",
    "* Unlike homework #3, use all columns of the dataset for this analysis*\n",
    "\n",
    "What to do:\n",
    "\n",
    "* Replace any missing values with zeros.\n",
    "* Apply a logarithmic transformation to the target variable median_house_value.\n",
    "* Divide the dataset into train, validation, and test sets with a 60%/20%/20% split.\n",
    "* Use the train_test_split function from scikit-learn and set the random_state parameter to 1 for reproducibility.\n",
    "* Use DictVectorizer(sparse=True) to convert the dataframes into sparse matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T14:42:39.450357900Z",
     "start_time": "2024-10-25T14:42:31.331154100Z"
    }
   },
   "outputs": [],
   "source": [
    "#do all the preprocessing steps above here:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T14:42:39.536480400Z",
     "start_time": "2024-10-25T14:42:39.457340700Z"
    }
   },
   "outputs": [],
   "source": [
    "housing_data = pd.read_csv('housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T14:42:39.537476900Z",
     "start_time": "2024-10-25T14:42:39.518031300Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_data = housing_data[housing_data['ocean_proximity'].isin(['<1H OCEAN', 'INLAND'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "filtered_data.loc[:, :] = filtered_data.fillna(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T14:42:39.554572100Z",
     "start_time": "2024-10-25T14:42:39.531493600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "filtered_data.loc[:, 'median_house_value'] = np.log(filtered_data['median_house_value'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T14:42:39.594611200Z",
     "start_time": "2024-10-25T14:42:39.553574Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(filtered_data, test_size=0.4, random_state=1)\n",
    "val_data, test_data = train_test_split(test_data, test_size=0.5, random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T14:42:39.596607Z",
     "start_time": "2024-10-25T14:42:39.565437600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "dv = DictVectorizer(sparse=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T14:42:39.597604100Z",
     "start_time": "2024-10-25T14:42:39.585123100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "X_train = dv.fit_transform(train_data.drop(columns=['median_house_value']).to_dict(orient='records'))\n",
    "X_val = dv.transform(val_data.drop(columns=['median_house_value']).to_dict(orient='records'))\n",
    "X_test = dv.transform(test_data.drop(columns=['median_house_value']).to_dict(orient='records'))\n",
    "\n",
    "y_train = train_data['median_house_value']\n",
    "y_val = val_data['median_house_value']\n",
    "y_test = test_data['median_house_value']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T14:42:39.892069300Z",
     "start_time": "2024-10-25T14:42:39.591620400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 1**\n",
    "Train a decision tree regressor with max_depth=1 to predict median_house_value.\n",
    "\n",
    " Identify which feature is used for the root split?:\n",
    "\n",
    "- ocean_proximity\n",
    "- total_rooms\n",
    "- latitude\n",
    "- population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ocean_proximity=INLAND\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor(max_depth=1, random_state=1)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "root_feature = dv.feature_names_[dt.tree_.feature[0]]\n",
    "print(\"Answer:\", root_feature)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T14:42:40.538783300Z",
     "start_time": "2024-10-25T14:42:39.897056500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 2**\n",
    "Train a random forest regressor with:\n",
    "* 10 trees (n_estimators=10), \n",
    "* random_state=1,\n",
    "*  n_jobs=-1. \n",
    "\n",
    "What is the RMSE of this model on the validation dataset?:\n",
    "\n",
    "- 0.045\n",
    "- 0.245\n",
    "- 0.545\n",
    "- 0.845"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T14:42:42.351127900Z",
     "start_time": "2024-10-25T14:42:40.540777200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE answеr: 0.235\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=10, random_state=1, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_val = rf.predict(X_val)\n",
    "rmse_val = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "print(\"RMSE answеr:\", round(rmse_val, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 3**\n",
    "Experiment with the random forest model:\n",
    "\n",
    "* Vary n_estimators from 10 to 200 in steps of 10\n",
    "* Keep random_state=1\n",
    "* Evaluate RMSE on the validation set for each n_estimators value\n",
    "\n",
    "Determine at which n_estimators value the RMSE stops improving (consider to 3 decimal places)?: \n",
    "\n",
    "- 10\n",
    "- 25\n",
    "- 50\n",
    "- 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T14:48:35.844950Z",
     "start_time": "2024-10-25T14:42:42.354121400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальное количество деревьев: 150\n"
     ]
    }
   ],
   "source": [
    "n_estimators_range = range(10, 201, 10)\n",
    "rmse_values = []\n",
    "\n",
    "for n in n_estimators_range:\n",
    "    rf = RandomForestRegressor(n_estimators=n, random_state=1, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_val = rf.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "    rmse_values.append(rmse)\n",
    "\n",
    "best_n_estimators = n_estimators_range[np.argmin(rmse_values)]\n",
    "print(\"Оптимальное количество деревьев:\", best_n_estimators)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 4**\n",
    "Experiment to find the best max_depth for the random forest.\n",
    "What to do:\n",
    "* Test max_depth values: 10, 15, 20, 25\n",
    "* For each max_depth vary n_estimators from 10 to 200 (step 10)\n",
    "* Calculate mean RMSE across all n_estimators\n",
    "* Use random_state=1\n",
    "\n",
    "Identify the best max_depth utilazing  mean RMSE? \n",
    "\n",
    "- 10\n",
    "- 15\n",
    "- 20\n",
    "- 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T14:48:35.850098200Z",
     "start_time": "2024-10-25T14:48:35.840683300Z"
    }
   },
   "outputs": [],
   "source": [
    "max_depth_values = [10, 15, 20, 25]\n",
    "n_estimators_range = range(10, 210, 10)\n",
    "random_state = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE(feature : max_depth): {10: 0.2326386603841415, 15: 0.22358645186317871, 20: 0.22262417744647184, 25: 0.22276327257114859}\n",
      "Best tree depth (max_depth): 20\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "mean_rmse_dict = {}\n",
    "\n",
    "for max_depth in max_depth_values:\n",
    "    rmse_list = []\n",
    "    for n_estimators in n_estimators_range:\n",
    "\n",
    "        rf_model = RandomForestRegressor(max_depth=max_depth, n_estimators=n_estimators, random_state=random_state)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = rf_model.predict(X_val)\n",
    "\n",
    "        rmse = sqrt(mean_squared_error(y_val, y_pred))\n",
    "        rmse_list.append(rmse)\n",
    "\n",
    "    mean_rmse_dict[max_depth] = np.mean(rmse_list)\n",
    "\n",
    "best_max_depth = min(mean_rmse_dict, key=mean_rmse_dict.get)\n",
    "\n",
    "print(\"Average RMSE(feature : max_depth):\", mean_rmse_dict)\n",
    "print(\"Best tree depth (max_depth):\", best_max_depth)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T16:02:37.329696400Z",
     "start_time": "2024-10-25T14:48:35.852214700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 5**\n",
    "Tree-based models use a \"gain\" metric when splitting nodes, measuring the reduction in impurity before and after each split. This gain helps identify important features. In scikit-learn, this information is stored in the feature_importances_ attribute\n",
    "\n",
    "Train a random forest model with these parameters:\n",
    "\n",
    "* n_estimators=10\n",
    "* max_depth=20\n",
    "* random_state=1\n",
    "* n_jobs=-1 (optional)\n",
    "\n",
    "Extract the feature importance information from the trained model. \n",
    "\n",
    "Identify and report the most important feature among the top 4 features based on their importance scores.\n",
    "\n",
    "What's the most important feature among these 4?: \n",
    "- total_rooms\n",
    "- median_income \n",
    "- total_bedrooms\n",
    "- longitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T16:02:38.651447600Z",
     "start_time": "2024-10-25T16:02:37.335859100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important feature: median_income\n"
     ]
    }
   ],
   "source": [
    "dv = DictVectorizer(sparse=True)\n",
    "X_train = dv.fit_transform(train_data.drop(columns=['median_house_value']).to_dict(orient='records'))\n",
    "y_train = train_data['median_house_value']\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=10, max_depth=20, random_state=1, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "feature_importances = rf_model.feature_importances_\n",
    "\n",
    "feature_names = dv.get_feature_names_out()\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "top_4_features = importance_df[importance_df['Feature'].isin(['total_rooms', 'median_income', 'total_bedrooms', 'longitude'])].sort_values(by='Importance', ascending=False)\n",
    "\n",
    "most_important_feature = top_4_features.iloc[0]['Feature']\n",
    "print(f\"Most important feature: {most_important_feature}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
